{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_wrapper import *\n",
    "from src.networks import *\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pickle \n",
    "      \n",
    "device = 'cuda:0'\n",
    "net_params = {\n",
    "    \"relation_dim\": 23,\n",
    "    \"object_dim\": 8,\n",
    "    \"hidden_dim\": 256,\n",
    "\n",
    "}\n",
    "dataset_params = {\n",
    "    \"device\": device,\n",
    "    \"path\": 'Data/articulated_joint_mass_9/',\n",
    "    \"num_of_traj\": 32000,\n",
    "    \"device\": device,\n",
    "    \"data_split\": (30000, 1000, 1000),\n",
    "    \"batch_size_train\": 16,\n",
    "    \"batch_size_val\": 32,\n",
    "    'num_workers': 4,\n",
    "    \"num_of_batch_train\": (0, 0), #(0, 10000),\n",
    "    \"num_of_batch_val\":(0, 0), #(0, 500),\n",
    "    'no_angle': False,\n",
    "    'shuffle': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = PropagationNetwork(**net_params).to(device)\n",
    "\n",
    "dataset_params['Network'] = Net\n",
    "\n",
    "dataset = DatasetWrapper(**dataset_params)\n",
    "\n",
    "with open('scaler.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset.scaler, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net.load_state_dict(torch.load('articulated.pt'),strict=False)\n",
    "Net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6_params = {\n",
    "    \"device\": device,\n",
    "    \"path\": 'Data/articulated_joint_mass_6/',\n",
    "    \"num_of_traj\": 1000,\n",
    "    \"device\": device,\n",
    "    \"data_split\": (0, 0, 1000),\n",
    "    \"batch_size_train\": 16,\n",
    "    \"batch_size_val\": 32,\n",
    "    'num_workers': 4,\n",
    "    \"num_of_batch_train\": (0, 0), #(0, 10000),\n",
    "    \"num_of_batch_val\":(0, 0), #(0, 500),\n",
    "    'shuffle': True,\n",
    "    'for_br_onestep':False,    \n",
    "    'no_angle': False,\n",
    "    \"scaler\": dataset.scaler\n",
    "}\n",
    "dataset6_params['Network'] = Net\n",
    "\n",
    "dataset6 = DatasetWrapper(**dataset6_params)\n",
    "\n",
    "dataset12_params = {\n",
    "    \"device\": device,\n",
    "    \"path\": 'Data/articulated_joint_mass_12/',\n",
    "    \"num_of_traj\": 1000,\n",
    "    \"device\": device,\n",
    "    \"data_split\": (0, 0, 1000),\n",
    "    \"batch_size_train\": 16,\n",
    "    \"batch_size_val\": 32,\n",
    "    'num_workers': 4,\n",
    "    \"num_of_batch_train\": (0, 0), #(0, 10000),\n",
    "    \"num_of_batch_val\":(0, 0), #(0, 500),\n",
    "    'shuffle': True,\n",
    "    'for_br_onestep':False,    \n",
    "    'no_angle': False,\n",
    "    \"scaler\": dataset.scaler\n",
    "}\n",
    "\n",
    "dataset12_params['Network'] = Net\n",
    "\n",
    "dataset12 = DatasetWrapper(**dataset12_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physics Prediction Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "metric1 = torch.nn.MSELoss(reduction='none')\n",
    "metric2 = torch.nn.MSELoss()\n",
    "\n",
    "def error_position(dataset, predicted):\n",
    "    error_over_time=list()\n",
    "    for t in range(1,50):\n",
    "        error = (dataset.val_tester.test_states[:, :t, 1:, 0:2]-predicted[:, :t, 1:, 0:2]).norm(dim=-1)\n",
    "        error_over_time.append(100*error.mean(dim=[1,2]).cpu().numpy())\n",
    "    return error_over_time\n",
    "\n",
    "def error_angle(dataset,predicted):\n",
    "    error_over_time=list()\n",
    "    for t in range(1,50):\n",
    "        error_over_time.append(np.sqrt(metric2(dataset.val_tester.test_states[:, :t, :, 2:3], predicted[:, :t, :, 2:3]).item())/np.pi*180)\n",
    "    return error_over_time\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    with torch.no_grad():\n",
    "        predicted9 = dataset.val_tester.test_pp()\n",
    "        error_pos9 = error_position(dataset,predicted9) \n",
    "        error_angle9 = error_angle(dataset,predicted9) \n",
    "        del predicted9\n",
    "        predicted6 = dataset6.val_tester.test_pp()\n",
    "        error_pos6 = error_position(dataset6,predicted6) \n",
    "        error_angle6 = error_angle(dataset6,predicted6) \n",
    "        del predicted6\n",
    "        predicted12 = dataset12.val_tester.test_pp()\n",
    "        error_pos12 = error_position(dataset12,predicted12) \n",
    "        error_angle12 = error_angle(dataset12,predicted12) \n",
    "        del predicted12        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,2,figsize=(12,15))\n",
    "num_of_objects=['9 ','6 ','12' ]\n",
    "for ind,error_pos in enumerate([error_pos9,error_pos6,error_pos12]):\n",
    "    ax[ind,0].set_ylabel(num_of_objects[ind]+'Objects',fontsize=24)\n",
    "    bins_ = [-1.5,-0.5,0.5,1.5,2.5,3.5,4.5,5.5]\n",
    "    xticks =[-1,0,1,2,3,4,5]\n",
    "    xtick_labels = ['< 0.1 cm','0.1-0.2 cm','0.2-0.4 cm','0.4-0.8 cm','0.8-1.6 cm', '1.6-3.2 cm','> 3.2 cm']\n",
    "\n",
    "    data = np.log2(10*error_pos[28])\n",
    "    data[data<-1.]=-1\n",
    "    ax[ind,0].set_axisbelow(True)\n",
    "    ax[ind,0].grid()\n",
    "    ax[ind,0].hist(data,bins=bins_,color='gray',rwidth=0.8)\n",
    "\n",
    "\n",
    "    data = np.log2(10*error_pos[48])\n",
    "    data[data<-1.]=-1\n",
    "    ax[ind,1].set_axisbelow(True)\n",
    "    ax[ind,1].grid()    \n",
    "    ax[ind,1].hist(data,bins=bins_,color='gray',rwidth=0.8)\n",
    "\n",
    "ax[0,0].set_title('Timestep 30',fontsize=20)\n",
    "ax[0,1].set_title('Timestep 50',fontsize=20)\n",
    "for i in range(3):\n",
    "    plt.sca(ax[i,0])\n",
    "    plt.xticks(xticks,[])\n",
    "    plt.sca(ax[i,1])\n",
    "    plt.xticks(xticks,[])\n",
    "    ax[i,1].yaxis.set_ticklabels([])\n",
    "    ax[i,0].set_ylim([0,1050])\n",
    "    ax[i,1].set_ylim([0,1050])\n",
    "    \n",
    "for i in range(3):\n",
    "    plt.sca(ax[i,0])\n",
    "    if i==2:\n",
    "        plt.xticks(xticks,xtick_labels,rotation=45,fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.sca(ax[i,1])\n",
    "    if i==2:\n",
    "        plt.xticks(xticks,xtick_labels,rotation=45,fontsize=16)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"articulated_pp.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belief Regulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all joint baseline relations\n",
    "# This operation is slow, so its not in base code.\n",
    "import collision\n",
    "def all_joint_criteria(obj_info, obj_info2):\n",
    "    # Object 1    \n",
    "    if obj_info['type']==0:\n",
    "        center_object = collision.Vector(obj_info['position'][0],obj_info['position'][1])\n",
    "        obj1 =collision.Circle(center_object, (obj_info['shape'][0])/2+0.05)\n",
    "    elif obj_info['type']==1:\n",
    "        center_object = collision.Vector(obj_info['position'][0],obj_info['position'][1])\n",
    "        obj1 =collision.Poly.from_box(center_object, obj_info['shape'][0]+0.05,obj_info['shape'][1]+0.05)\n",
    "        obj1.angle = obj_info['angle']\n",
    "    if obj_info2['type']==0:\n",
    "        center_object = collision.Vector(obj_info2['position'][0],obj_info2['position'][1])\n",
    "        obj2 =collision.Circle(center_object, (obj_info2['shape'][0])/2+0.05)\n",
    "    elif obj_info2['type']==1:\n",
    "        center_object = collision.Vector(obj_info2['position'][0],obj_info2['position'][1])\n",
    "        obj2 =collision.Poly.from_box(center_object, obj_info2['shape'][0]+0.05,obj_info2['shape'][1]+0.05)\n",
    "        obj2.angle = obj_info2['angle']\n",
    "\n",
    "    # Maybe too much bias.\n",
    "    if obj_info['type'] == 1 and obj_info2['type'] ==1:\n",
    "        if abs((obj_info['angle']-obj_info2['angle'])%np.pi/2)>1e-5:\n",
    "            return False \n",
    "\n",
    "    return collision.collide(obj1,obj2)\n",
    "def find_all_fixed_baseline(dataset):\n",
    "    test_rels_all_fixed = torch.stack([dataset.val_tester.test_rels] * 200 , dim=1)\n",
    "    test_rels_all_fixed[:,:,:,:]=0\n",
    "    n_of_obj=dataset.val_tester.num_of_objects\n",
    "    test_rels_all_fixed[:,:,:,0]=1\n",
    "    for traj_ind in tqdm(range(1000)):\n",
    "        traj_len = min(200, dataset.val_tester.test_traj_lens[traj_ind])\n",
    "        for ts in range(traj_len):\n",
    "            cnt=0\n",
    "            for i in range(n_of_obj):\n",
    "                for j in range(n_of_obj):\n",
    "                    if i!=j:\n",
    "                        if i!=0 or j!=0:\n",
    "                            obj_info=dict()\n",
    "                            obj_info2=dict()                    \n",
    "                            obj_info['type']  = int(dataset.val_tester.test_shapes[traj_ind,i,1])\n",
    "                            obj_info2['type'] = int(dataset.val_tester.test_shapes[traj_ind,j,1]) \n",
    "                            obj_info['position']  = dataset.val_tester.test_states[traj_ind,ts,i,:2].tolist()\n",
    "                            obj_info2['position'] = dataset.val_tester.test_states[traj_ind,ts,j,:2].tolist()\n",
    "                            obj_info['angle']  = dataset.val_tester.test_states[traj_ind,ts,i,2].tolist()\n",
    "                            obj_info2['angle'] = dataset.val_tester.test_states[traj_ind,ts,j,2].tolist()                    \n",
    "                            obj_info['shape']  = dataset.val_tester.test_shapes[traj_ind,i,-2:].tolist()\n",
    "                            obj_info2['shape'] = dataset.val_tester.test_shapes[traj_ind,j,-2:].tolist()\n",
    "                            if all_joint_criteria(obj_info, obj_info2):\n",
    "                                test_rels_all_fixed[traj_ind,ts,cnt,0]=0\n",
    "                                test_rels_all_fixed[traj_ind,ts,cnt,1]=1\n",
    "                        cnt=cnt+1\n",
    "        test_rels_all_fixed[traj_ind,traj_len:,:,:] = test_rels_all_fixed[traj_ind,traj_len-1,:,:]\n",
    "    return  test_rels_all_fixed\n",
    "test_rels_all_fixed = find_all_fixed_baseline(dataset)\n",
    "test_rels_all_fixed6 = find_all_fixed_baseline(dataset6)\n",
    "test_rels_all_fixed12 = find_all_fixed_baseline(dataset12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_rels_all_fixed,'test_rels_all_fixed9_2.pt')\n",
    "torch.save(test_rels_all_fixed6,'test_rels_all_fixed6_2.pt')\n",
    "torch.save(test_rels_all_fixed12,'test_rels_all_fixed12_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rels_all_fixed = dict()\n",
    "for n_of_obj in [9,6,12]:\n",
    "    test_rels_all_fixed[n_of_obj] = torch.load('test_rels_all_fixed'+str(n_of_obj)+'_2.pt',map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rels_br = dict()\n",
    "test_rels_oracle = dict()\n",
    "\n",
    "datasets = dict()\n",
    "datasets[9] = dataset\n",
    "datasets[6] = dataset6\n",
    "datasets[12] = dataset12      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    with torch.no_grad():\n",
    "        for n_of_obj in [12,9,6]:\n",
    "            predicted_br, ground_truth = datasets[n_of_obj].val_tester.test_br(batch_size=12)\n",
    "            test_rels_br[n_of_obj] = predicted_br['rel_to_predict'].cpu() \n",
    "            test_rels_oracle[n_of_obj] = ground_truth['rel_to_predict'].cpu() \n",
    "            del predicted_br, ground_truth\n",
    "for obj_n in [9,6,12]:\n",
    "    torch.save(test_rels_br[obj_n],'test_rels_'+str(obj_n)+'.pt')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rels_all_fixed = dict()\n",
    "test_rels_all_fixed_prev = dict()\n",
    "test_rels_oracle = dict()\n",
    "test_rels_br = dict()\n",
    "\n",
    "for n_of_obj in [9,6,12]:\n",
    "    test_rels_all_fixed_prev[n_of_obj] = torch.load('test_rels_all_fixed'+str(n_of_obj)+'.pt',map_location=torch.device('cpu'))    \n",
    "    test_rels_all_fixed[n_of_obj] = torch.load('test_rels_all_fixed'+str(n_of_obj)+'_2.pt',map_location=torch.device('cpu'))\n",
    "    test_rels_oracle[n_of_obj] = torch.stack([datasets[n_of_obj].val_tester.test_rels] * 200, dim=1) \n",
    "    test_rels_br[n_of_obj] = torch.load('test_rels_'+str(n_of_obj)+'.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracyOverTime(ypred, ytarget):\n",
    "    return ((ypred.max(dim=-1)[1] == ytarget.max(dim=-1)[1])*1.0).mean(dim=[0, 2]).cpu().numpy()\n",
    "accuracy_over_time_BR=dict()\n",
    "accuracy_over_time_NJ=dict()\n",
    "accuracy_over_time_AJ=dict()\n",
    "accuracy_over_time_AJ_old=dict()\n",
    "\n",
    "for n_of_obj in [9,6,12]:\n",
    "    accuracy_over_time_BR[n_of_obj] = getAccuracyOverTime(test_rels_br[n_of_obj], test_rels_oracle[n_of_obj])\n",
    "    accuracy_over_time_NJ[n_of_obj] = getAccuracyOverTime(datasets[n_of_obj].val_tester.test_rels_no_joint, test_rels_oracle[n_of_obj])\n",
    "    accuracy_over_time_AJ[n_of_obj] = getAccuracyOverTime(test_rels_all_fixed[n_of_obj], test_rels_oracle[n_of_obj])\n",
    "    accuracy_over_time_AJ_old[n_of_obj] = getAccuracyOverTime(test_rels_all_fixed_prev[n_of_obj], test_rels_oracle[n_of_obj])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_gt = test_rels_oracle[9].max(dim=-1)[1]\n",
    "labels_predicted = test_rels_br[9].max(dim=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(/(labels_gt[:,-1]==2).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels_gt==0).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16076000/(1000*200*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions= dict()\n",
    "recalls = dict()\n",
    "for n_of_obj in [9,6,12]:\n",
    "    labels_gt = test_rels_oracle[n_of_obj].max(dim=-1)[1]\n",
    "    labels_predicted = test_rels_br[n_of_obj].max(dim=-1)[1]\n",
    "    for relation in range(4):\n",
    "        precisions[(n_of_obj,relation)]=np.zeros((20,))\n",
    "        recalls[(n_of_obj,relation)]=np.zeros((20,))\n",
    "        for ind,ts in enumerate(range(0,200,10)):\n",
    "            Y = labels_gt[:,ts] == relation\n",
    "            h = labels_predicted[:,ts] == relation    \n",
    "            Ynh = (torch.logical_and(Y,h)).sum().item()\n",
    "            precision = Ynh/h.sum().item()\n",
    "            recall = Ynh/Y.sum().item()\n",
    "            precisions[(n_of_obj,relation)][ind]=precision\n",
    "            recalls[(n_of_obj,relation)][ind]=recall         \n",
    "#             print(str(n_of_obj)+\" Object at timestep -1 precision: \"+str(precision)+\" recall: \"+str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_type = ['No Joint','Fixed Joint','Prismatic Joint','Revolute Joint']\n",
    "fig,ax = plt.subplots(1,2,figsize=(11,5),dpi=100)\n",
    "for relation in range(4):\n",
    "    precision = (precisions[9,relation]+precisions[6,relation]+precisions[12,relation])/3\n",
    "    ax[0].plot(range(10,200,10),precision[1:],label=relation_type[relation],lw=4)\n",
    "for relation in range(4):\n",
    "    recall = (recalls[9,relation]+recalls[6,relation]+recalls[12,relation])/3\n",
    "    ax[1].plot(range(10,200,10),recall[1:],label=relation_type[relation],lw=4)\n",
    "plt.legend(fontsize=18)\n",
    "for i in range(2):\n",
    "    ax[i].set_xticks(range(0,201,40)) \n",
    "    ax[i].tick_params(labelsize=16,labelrotation=45)\n",
    "    ax[i].set_ylim([0,1.05])\n",
    "    ax[0].set_xlabel(\"Number of Observed Timesteps\",fontsize=20)\n",
    "ax[0].set_title(\"Precision\",fontsize=20)\n",
    "ax[1].set_title(\"Recall\",fontsize=20)\n",
    "ax[1].yaxis.set_ticklabels([])\n",
    "ax[1].grid()\n",
    "ax[0].grid()\n",
    "\n",
    "fig.savefig(\"Articulated_Prec_recall.png\",bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(12,5))\n",
    "for ind, n_of_obj in enumerate([9,6,12]):\n",
    "\n",
    "    ax[ind].plot(accuracy_over_time_BR[n_of_obj],label='Belief Regulation',lw=4,ls=':',color='gray')\n",
    "    ax[ind].plot(accuracy_over_time_NJ[n_of_obj],label='No Joint',lw=4,ls='--',color='gray')\n",
    "    ax[ind].plot(accuracy_over_time_AJ[n_of_obj],label='All Fixed Joints',lw=4,color='gray')\n",
    "    ax[ind].set_title(str(n_of_obj) + \" Objects\",fontsize=16)\n",
    "\n",
    "ax[1].set_xlabel('Number of Observed Timestep',fontsize=16)\n",
    "ax[0].set_ylabel('Joint Prediction Accuracy',fontsize=16)\n",
    "ax[2].legend(fontsize=12)\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"Articulated_br_baselines.png\",bbox_inches='tight')\n",
    "plt.show()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_over_time_BR[n_of_obj].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5),dpi=100)\n",
    "for ind, n_of_obj in enumerate([9,6,12]):\n",
    "    ax.plot(range(10,200),accuracy_over_time_BR[n_of_obj][10:],label=str(n_of_obj)+' Objects',lw=4)\n",
    "ax.set_title(\"Joint Prediction Accuracy\",fontsize=20)\n",
    "\n",
    "ax.set_xlabel('Number of Observed Timesteps',fontsize=20)\n",
    "ax.legend(fontsize=18)\n",
    "fig.tight_layout()\n",
    "ax.set_xticks(range(0,201,40)) \n",
    "ax.tick_params(labelsize=16,labelrotation=45)\n",
    "plt.grid()\n",
    "plt.savefig(\"articulated_br_n_of_obj.png\",bbox_inches='tight')\n",
    "plt.show()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coupled Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def test_pp_custom(dataset, joint_rels, start_timestep, end_timestep):\n",
    "    number_of_timestep = end_timestep - start_timestep\n",
    "    to_be_pred = dataset.val_tester.test_states.clone()[:,start_timestep:end_timestep].to(device)\n",
    "    to_be_pred[:, 1:, 1:, :] = 0\n",
    "    batch_size = 100\n",
    "    for batch in range(10):\n",
    "        x = dict()\n",
    "        x['objects_shape'] = dataset.val_tester.test_shapes[batch*100:(batch+1)*100].to(device)\n",
    "        x['relation_info'] = joint_rels[batch*100:(batch+1)*100].to(device)\n",
    "        for timestep in range(1, number_of_timestep):\n",
    "            x['objects_state'] = to_be_pred[batch*100:(batch+1)*100, timestep-1, :, :]\n",
    "            to_be_pred[batch*100:(batch+1)*100, timestep, 1:, :6] = dataset.gp_pp(x)\n",
    "        del x\n",
    "    to_be_pred_cpu = to_be_pred.cpu()\n",
    "    del to_be_pred\n",
    "    gc.collect()\n",
    "    return to_be_pred_cpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertOneHot(probs):\n",
    "    max_idx = torch.argmax(probs, -1, keepdim=True)\n",
    "    one_hot = torch.FloatTensor(probs.shape)\n",
    "    one_hot.zero_()\n",
    "    one_hot.scatter_(-1, max_idx, 1)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric2 = torch.nn.MSELoss()\n",
    "\n",
    "def error_position(gt, predicted):\n",
    "    return 100*np.sqrt(metric2(gt,predicted).cpu().numpy())\n",
    "errors_mean =dict()\n",
    "errors_standart =dict()\n",
    "\n",
    "dataset_rels=dict()\n",
    "for n_of_obj in [9,6,12]:\n",
    "    dataset_rels['Oracle',n_of_obj] = test_rels_oracle[n_of_obj]\n",
    "    dataset_rels['BR',n_of_obj] = convertOneHot(test_rels_br[n_of_obj])\n",
    "    dataset_rels['No-Joint',n_of_obj] = datasets[n_of_obj].val_tester.test_rels_no_joint\n",
    "    dataset_rels['All-Fixed',n_of_obj] = test_rels_all_fixed[n_of_obj]\n",
    "\n",
    "for baseline in ['Oracle','BR','No-Joint','All-Fixed']:\n",
    "    for n_of_obj in [9,6,12]:\n",
    "        errors_mean[baseline,n_of_obj] = list()\n",
    "        errors_standart[baseline,n_of_obj] = list()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    with torch.no_grad():\n",
    "        for ts in range(0,101,10):\n",
    "            for n_of_obj in [9,6,12]:\n",
    "                gt_traj = datasets[n_of_obj].val_tester.test_states[:,ts:ts+50,:,:2]\n",
    "                for baseline in ['Oracle','BR','No-Joint','All-Fixed']: #\n",
    "                    print(ts,n_of_obj,baseline)\n",
    "                    predicted = test_pp_custom(datasets[n_of_obj], dataset_rels[baseline,n_of_obj][:,ts], ts, ts+50)\n",
    "                    errors= (100*(gt_traj[:,:,1:]-predicted[:,:,1:,:2]).norm(dim=-1)).mean(dim=[1,2])\n",
    "                    print(errors.shape)\n",
    "                    err_mean= errors.mean().item()\n",
    "                    err_standart = errors.std().item()/np.sqrt(1000)                    \n",
    "                    errors_mean[baseline,n_of_obj].append(err_mean)\n",
    "                    errors_standart[baseline,n_of_obj].append(err_standart)\n",
    "\n",
    "                    del predicted, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(15,5),dpi=200)\n",
    "for ind, n_of_obj in enumerate([9,6,12]):\n",
    "    for baseline in ['Oracle','BR','No-Joint','All-Fixed']:\n",
    "        err_me = np.array(errors_mean[baseline,n_of_obj])[:]\n",
    "        err_standart = np.array(errors_standart[baseline,n_of_obj])[:]\n",
    "        ax[ind].plot(range(0,101,10),err_me,label=baseline,lw=4)\n",
    "        ax[ind].fill_between(range(0,101,10),err_me-err_standart,err_me+err_standart,alpha=0.25)        \n",
    "    ax[ind].set_title(str(n_of_obj) + \" Objects\",fontsize=20)\n",
    "    ax[ind].set_ylim([-0.1,7.2])\n",
    "ax[1].yaxis.set_ticklabels([])\n",
    "ax[2].yaxis.set_ticklabels([])\n",
    "\n",
    "\n",
    "ax[1].set_xlabel('Number of Observed Timesteps',fontsize=20)\n",
    "ax[0].set_ylabel('50 Timestep Rollout Error (cm)',fontsize=20)\n",
    "ax[1].legend(fontsize=18)\n",
    "for i in range(3):\n",
    "    ax[i].tick_params(labelsize=16)\n",
    "    ax[i].set_axisbelow(True)\n",
    "    ax[i].grid()\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"articulated_full.png\",bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_nn2",
   "language": "python",
   "name": "sim_nn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
